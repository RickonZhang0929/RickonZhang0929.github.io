(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{428:function(v,_,r){"use strict";r.r(_);var n=r(2),t=Object(n.a)({},(function(){var v=this,_=v._self._c;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("h1",{attrs:{id:"机器学习笔记"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#机器学习笔记"}},[v._v("#")]),v._v(" 机器学习笔记")]),v._v(" "),_("h2",{attrs:{id:"参考网站"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#参考网站"}},[v._v("#")]),v._v(" 参考网站")]),v._v(" "),_("p",[v._v("李宏毅机器学习笔记  "),_("code",[v._v("https://datawhalechina.github.io/leeml-notes/#/")]),_("br"),v._v("\n吴恩达深度学习笔记  "),_("code",[v._v("https://kyonhuang.top/Andrew-Ng-Deep-Learning-notes/#/")]),_("br"),v._v("\n吴恩达机器学习代码  "),_("code",[v._v("https://www.heywhale.com/home/column/5dd7524c83b6ff002c786fff")]),_("br"),v._v("\neasyAI 网站"),_("code",[v._v("https://easyai.tech/ai-definition-category/machine-learning/")])]),v._v(" "),_("h2",{attrs:{id:"机器学习分类"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#机器学习分类"}},[v._v("#")]),v._v(" 机器学习分类")]),v._v(" "),_("p",[v._v("机器利用数据学习逻辑和算法"),_("br"),v._v("\n主要分类：")]),v._v(" "),_("ul",[_("li",[v._v("无监督：给数据，无标注，聚类问题")]),v._v(" "),_("li",[v._v("监督：给数据，给标注，分类或回归问题")]),v._v(" "),_("li",[v._v("强化：给状态，动作，奖励，获得动作策略")])]),v._v(" "),_("p",[v._v("神经网络 是基于 逻辑回归（监督学习）"),_("br"),v._v("\n深度学习 是基于 神经网络")]),v._v(" "),_("h2",{attrs:{id:"ai层级"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#ai层级"}},[v._v("#")]),v._v(" AI层级")]),v._v(" "),_("p",[v._v("基础：数据和硬件算力"),_("br"),v._v("\n算法：机器学习和深度学习的相关算法"),_("br"),v._v("\n方向：CV，NLP，语音，决策，搜索"),_("br"),v._v("\n具体：机器翻译，语义理解"),_("br"),v._v("\n方案：智能安防")]),v._v(" "),_("h2",{attrs:{id:"简单代码流程"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#简单代码流程"}},[v._v("#")]),v._v(" 简单代码流程")]),v._v(" "),_("p",[v._v("1·读取数据"),_("br"),v._v("\n2·矩阵化和标准化处理"),_("br"),v._v("\n3·算法函数"),_("br"),v._v("\n4·设置参数的初始值"),_("br"),v._v("\n5·代入计算结果"),_("br"),v._v("\n6·可视化展示")]),v._v(" "),_("h2",{attrs:{id:"决策树"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#决策树"}},[v._v("#")]),v._v(" 决策树")]),v._v(" "),_("p",[v._v("信息熵"),_("br"),v._v("\n不确定程度"),_("br"),v._v("\n可能的不确定度的期望"),_("br"),v._v("\n对概率进行映射"),_("br"),v._v("\n满足非负，连续，独立事件概率相乘不确定度相加")]),v._v(" "),_("p",[v._v("三个性质作为不确定度"),_("br"),v._v("\n-log（p）采用负对数")]),v._v(" "),_("p",[v._v("不确定度的期望是，不确定度乘概率求和"),_("br"),v._v("\n（事件的期望是 事件乘概率求和）")]),v._v(" "),_("p",[v._v("一个事件拆解成不同事件"),_("br"),v._v("\n求所有事件的不确定度的期望"),_("br"),v._v("\n便能衡量事件的信息量的大小")]),v._v(" "),_("p",[v._v("直观感受是事件的发生的概率越小"),_("br"),v._v("\nH的值越大说明信息越多"),_("br"),v._v("\nH值越小说明更加确定"),_("br"),v._v("\n差值是条件改变产生的信息量"),_("br"),v._v("\nH可以直接量化信息")]),v._v(" "),_("p",[v._v("先将事件理解成一个概率分布的问题"),_("br"),v._v("\n不确定度就是分布情况的复杂度"),_("br"),v._v("\n熵最小时是完全确定的状态")]),v._v(" "),_("p",[v._v("对于二叉树而言"),_("br"),v._v("\n给出样本的属性\t"),_("br"),v._v("\n机器要做的是"),_("br"),v._v("\n1·将属性设定先后"),_("br"),v._v("\n2·找到阈值"),_("br"),v._v("\n比较不同属性正确率"),_("br"),v._v("\n尽可能提高正确率"),_("br"),v._v("\n这个过程就是减小熵")]),v._v(" "),_("p",[v._v("熵：随机变量的不确定度"),_("br"),v._v("\n条件熵：一个条件下 随机变量的不确定度"),_("br"),v._v("\n信息增益：熵-条件熵"),_("br"),v._v("\n不确定性的减少程度，即为我们带来了多少有用信息")]),v._v(" "),_("p",[v._v("举例解释\nX(明天下雨)是一个随机变量，X的熵可以算出来， Y(明天阴天)也是随机变量，在阴天情况下下雨的信息熵我们如果也知道的话（此处需要知道其联合概率分布或是通过数据估计）即是条件熵。X的熵减去Y条件下X的熵，就是信息增益。具体解释：原本明天下雨的信息熵是2，条件熵是0.01（因为如果知道明天是阴天，那么下雨的概率很大，信息量少），这样相减后为1.99。在获得阴天这个信息后，下雨信息不确定性减少了1.99，不确定减少了很多，所以信息增益大。也就是说，阴天这个信息对明天下午这一推断来说非常重要。所以在特征选择的时候常常用信息增益，如果IG（信息增益大）的话那么这个特征对于分类来说很关键，决策树就是这样来找特征的。")]),v._v(" "),_("p",[v._v("选信息增益最大的特征作为根节点"),_("br"),v._v("\n特征选择 选取具有分类能力的属性"),_("br"),v._v("\n决策树生成 选择特征作为节点，然后将取值作为子节点，直到特征被用完"),_("br"),v._v("\n决策树剪枝 对抗过拟合，预剪枝，后剪枝，然后对比和原来的效果")]),v._v(" "),_("h2",{attrs:{id:"支持向量机"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#支持向量机"}},[v._v("#")]),v._v(" 支持向量机")]),v._v(" "),_("p",[v._v("SVM"),_("br"),v._v("\n具体的推导过于抽象难以理解"),_("br"),v._v("\n包含的参数有 支持向量x，超平面，间隔d"),_("br"),v._v("\n目标函数是最大化边距"),_("br"),v._v("\n即最优超平面")]),v._v(" "),_("p",[v._v("通过目标函数和约束条件进行化简"),_("br"),v._v("\n通过对偶问题和核技巧和SMO得到W和b")]),v._v(" "),_("h2",{attrs:{id:"学习经验"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#学习经验"}},[v._v("#")]),v._v(" 学习经验")]),v._v(" "),_("p",[v._v("理解整体的含义"),_("br"),v._v("\n像代价函数，BP等底层算法"),_("br"),v._v("\n无需过多关注细节")]),v._v(" "),_("p",[v._v("无需过度关注算法和实现细节"),_("br"),v._v("\n只需要明白算法的架构和原理")])])}),[],!1,null,null,null);_.default=t.exports}}]);